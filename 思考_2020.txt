2020.12.23
自注意算法，如果解决自相关的影响？

2020.12.16
多头注意？多个小头和一个大头比较，除了速度和内存提升外，注意力效果上是否有提升？

2020.12.10
1.模型的图和变量（推理时保存为常量）有什么区别和联系？
2.具身认知，指具体化（embodiment），生理，心理，环境的相互作用的有机体

2020.12.02
早晨，刷牙，想着摸大宝，又想着买酸奶，应该是多任务状态，这时出错了，将大宝弄在牙膏上了，弄完后看到了，赶紧纠正。
说明大脑在多任务情况下，有一种监督，或者是异常的导致某一任务权重增加，专注和专业网络应该有很长额生命力，
多任务网络应该有监督或者动态的权重（推理阶段的）。

2020.12.01
如何在网络中加入记忆（常识，知识库），如何加入思考（可能是生成，推理，判断的形式）

2020.11.30
曹慧珍的离开的思考，可能原因：一个是物质方面的，一个是精神方面的；也可能都有。满足基本的物质需求，最大化激发精神的兴奋感，满足感！

2020.11.26
经典深度学习模型，cnn,rnn,gru,lstm等在做研究新理论新方法，甚至落地等方面还会有用的

2020.11.18
如果对GPT3进行剪枝，去稀疏处理等瘦化后，效果是怎么样的？但是这得等开源后再说了

2020.11.16
计算神经科学，从计算模型跟人类神经做比较，从而理解模型和人类神经
1）大脑使用生成模型和识别模型的组合，不仅是为了识别和表征物体，而且是为了推断场景中固有的因果结构，这一切都是在一瞬间发生的。
2）一个混合网络 ―― 在输入阶段之后有七个公共层，然后是两个分别为五层的独立网络 ―― 几乎和完全独立的网络做得一样好。
因此 McDermott 和他的同事选择了用最少的计算资源且工作得最好的混合网络。当他们让这个混合网络与人类在这些任务中的表现进行较量时，两者非常相似。

2020.11.13
下游开发或者设计不清楚怎么把ai技术应用起工作中，这就需要上游AI开发者更多的融入下游开发者问题讨论中，从ai角度提出解决方案;
具体可能是AI的接口人或者ai的领导或者骨干

2020.11.12
1.关于对比学习的思考，Supervised Contrastive Learning，SimCLR，来源于孩子认知初期的观察对比，有效提升了小样本问题解决程度；无论在开始的图像领域，
还是在文本处理,例如bert的loss中交叉熵CE基础上，增加SCL；灵感来源于基础的认知；同一种ai能力，是可以跨领域的，
2.对话机器人应该有个预设目标，是推荐目的，还是倾听目的，问题是如何去预设呢？pipeline框架的在对话策略那控制，
生成式框架在输入增加超参数或者在输出候选项后增加个过滤排序模型

2020.11.10
1.持续在线学习，例如，白天作为人的助手，学习人的经验与知识，晚上或者人倒休时替换人直接完成工作，同时会把处理不了的问题记录下来。唯一担心的是
人害怕被替代，而不能跟机器合作和学习。
2.首先要解决最新最好AI理论落地问题，其次在发现问题，解决问题中创新，大概率是微创新

2020.11.9
对话端到端模型哪个方向最有可能落地，既然pipeline能够落地，必然有其合理的地方，端到端必须以一种合理的方式达到pipeline各个部分效果，
假设是理解到目标到生成，目标是一种自动目标，或者是一种意识，例如催收，经过大量语料训练，模型模型能归纳到催收为核心目标;
也可以像人一样，在对话之前，已经明确对比目标是什么？给模型注入核心目标，可以在训练前，或者推理前。
最后怎么去实现？只要方向对，肯定有质变的那一刻

2020.11.4
人的学习效率为什么高于机器学习效率，基因传递是否有记忆功能（可能更是本能），大脑的神经结构和神经元数量，方法（与原知识联系，相同，相似，
相反，总结归纳，泛化等），记忆（短期，长期，日积月累），多维度信息提取，

2020.11.1
管理三明治：先转换新的角色，通过沟通的方式，在目标（金钱，理想）、人、事三个维度进行管理
具体问题具体分析，找到或者实验哪个理论或者方案更适合
管理和教育孩子是相通的，当好父母是你必须做好的角色
反思：ai研发部的定位是什么？理念是什么？沟通与学习，例如周例会应该是个总结，问题讨论，建议

2020.10.29
什么时候发现自已倚老卖老了，就应该离开了

2020.10.28
1.熊露离职，是一个思考组织或者团队问题的触发点或者机会
2.华科魏老师整合问题，如何让“研”到“产”落地？

2020.10.27
GPT-3首次完成剧本创作,AI创造力貌似是真的，文学创作可能来源于生活，来源于数据，至少这是一个突破口，或者突破方向；那科学的创造力来源于哪里，
来源于问题，来源于前人的一种思路或者方法论，来源于假设，来源于实验;人工智能离科学的创造力还有多远

2020.10.15
员工和企业是共赢关系，以共赢的原则为出发点，工作，沟通

2020.10.14
1.做人中庸一些，做技术坚持科学底线
2.共享学习
3.打比赛，最低要求拿到数据，最高要求专利，中间要求论文，文章

2020.10.13
1.持续研究开发一个多任务模型，例如意图识别，情感分析，验证大一统的模型可行性？
2.预训练模型，微调有优势，但是改结构成本有些大

2020.10.12
对话机器人最基本的就是理解基础上的回答

2020.10.10
生命的长度
活到孩子18岁
活到父母之后
活到妻子之后
活到理想之后

2020.09.30
个人认为，人的语言理解单元是句子，nlp应该也是以句子为理解单元

2020.09.29
怎么知道ai不行了，要切换为人工，是靠意图识别的置信度阀值，还是基于情感分析？

2020.09.28
1.已落地算法优化方向，可能是在这一方向的技术跟踪，储备，一种持续性深入，但不会轻易的更新到落地
2.各个大厂的对外nlp能力，尤其是阿里的，应该是算法备胎的一个简单方向
3.每个月定期的跟下游应用层，产品经理对下需求，落地为第一要务
4.降成本，对大厂的模型算法成本，提高并发处理能力，标注数据成本；

2020.09.27
1.公司的ai团队，合作的学习团队，怎么能够很好的整合呢？怕被跳到对方的坑里？如何的竞争与合作呢？
解决：设置主从关系，公司是主，学校是从；学习能拿出原形，证明道路可行可以了，他们更注重发论文；学校的要落地必须改造，不要想着拿来就能用
2.相似度的优化：我感觉bert嵌入，强于句式知识，词林强于人工语义，因此增加一种级联bert+cinlin，即先bert，后词林（不用关键词），速度会提升，效果是否会下降？；区别于cinlin+bert，先词林(先结巴关键词)，后bert，

2020.09.24
1.大数据如何应用nlp?
2.机器人种类路由应该是什么技术？闲聊机器人，任务机器人等之间的自有切换？

2020.09.22
1.文本顺滑：用来识别出口语中自带的不流畅文本。随着ASR/自动语音识别的流行，NLP相关系统获取到的用户口语文本往往含有大量的不流畅表述。这些不流畅表述的来源有两点：（1）ASR系统识别错误导致；（2）用户话中自带的。
2.魏老师团队的东西是否可以作为学习消化的一个源，就当丰富自己知识了。
例如：
聚类中bert的特性向量提取的是哪个层，pooler?

2020.09.21
1.模型直接理解声音或者音，例子：假如一群文盲，他们聊天，沟通都没问题。可能不好好落地吧，asr解决了基础问题，业务算法解决业务问题，可能更好落地吧
2.解决人与机器沟通与合作问题，语言是一种外部形式，脑机接口是一种内部形式。

2020.09.15
1.bert为什么用cls代表句向量，用于下游任务？我理解是因为每句话这个都是相同的位置和名称等嵌入信息
2.人机协同思想或者阶段，模型学习的是隐形知识，人掌握显性知识，

2020.09.14
bert为什么微调后，效果提升显著？肯定是一种知识迁移，是通用知识向专家知识迁移吗？还是通用知识从训练数据集分布向微调数据集分布迁移？
还有可能借用《常识知识确能被捕获，西湖大学博士探究BERT如何做常识问答》的解释，这表明对常识任务的监督训练可以增强结构化的常识知识。

2020.09.08
技术不能很好的解决问题，就会被淘汰，这就是技术的进化论

2020.08.21
1.用bert词向量做和为近似句向量，gtp3或者t5的词向量是不是更好呢？bert 词向量是怎么来的
2.相似度：先做消融实验即单个算法统计，再做融合实验

2020.08.19
1.AI算法储备（备胎）要到一种形式表现结果，代码，python,c++，java jni，是否非得要等李文超提需求？
2.云推理服务需要带宽，并发，延时，鉴权，gpu其他的等等问题，还是sdk方式灵活实用
3.数据增加不敢用于训练，可以先用于测试集，测试模型的泛化能力


2020.08.14
目前AI还是处于试验科学，黑盒科学层次；理论的突破口可能在于系统论，整体论。

2020.08.13
对话中有端到端模型直接把自然语言理解（natural language understanding），对话状态跟踪（dialog state tracker），对话策略学习（dialog policy），
自然语言生成（natural language generation）将这些步骤完全地包含在神经网络内部；在端到端还不能落地的情况下，模型步骤是否可以有限的包含到模型中呢


2020.08.06
1.convlab2下一部一个可能的方向，加入闲聊对话
2.对话研究几个层次：文本对话，语音对话（不仅仅是asr,还包括声调，频率的多模态多维度信息），音视频对话（面部表情，手式等多模态多维度信息），个体意识与性格的永生

2020.08.04
速度优先模型主要用于性能测试，和高负荷时使用；主要目标还是精度不将或者少降下的速度提升，用高性价比模型替换高质量模型发布，例如变长，fastbert等

2020.08.04
1.发现问题，发现机遇
2.slot填充或者命名实体，预测每一个tocken的tag分数

2020.08.03
技术储备（备胎）：投入产出比，
1.可快速落地的小技术（无到有）
2.变革的大技术，可能更是一些预研性质的
3.优化型技术（对已发布技术的持续优化）
4.落地形式：项目，产品，专利，代码，论文，报告

2020.07.27
1.基础技术部门，除了完成应用上层提出的需求外，战略眼光要高于应用一个层次或者提前一步，可以预研一下未来的技术，申请一些专利（公司更喜欢），发一些论文
2.训练的一些指标精度，召回率，F1等是个重要参考，但是最好把模型放到真实的对话中，实际体验到底如何，模型对对话的提升占比是多少，能提升多少对话体验效果

2020.07.23
发现问题，解决问题。无论大事小事，无论技术社会，都是通用的过程。发现问题，可能更需要个人的观察，批判，甚至是勇气；解决问题，需要智慧，坚持，团队合作，求同存异，资本等

2020.07.20
模型中很多超参数，好像是实验的人为干预，又好像类似物理定律中的一些系数
数据导向型，需要数据积累；知识导向性，需要知识积累；这些都需要，领域缓慢积累的过程；现在的预训练模型，表面是大数据，本质还是知识

2020.07.17
“持续而缓慢的学习，而不是临时抱佛脚，才能带来长久的成长。” ――吴恩达
“智慧不是学校教育的产物，而是终身学习的产物。” ――阿尔伯特・爱因斯坦

2020.07.16
cpu与gpu通信是个性能瓶颈，MIT教授 Nir Shavit，发现了再cpu上训练的软件改进算法，然后就于是他和MIT研究科学家 Alex Matveev 在 2017 年合伙创办了
一家名为公司Neural Magic的公司，宣称能通过一种“专有算法”让计算机在不配备专用硬件的前提下，运行复杂的数学函数，并使用更大规模的数据集。

2020.07.15
非常实用的，集聚创新的，非常好的论文，一定要多看几遍，例如蒸馏对与推理加速就相当的实用

2020.07.02
端到端的对话模型，是多任务模型，还是综合单任务模型；至少多任务模型可以降低任务型对话的成本，同时输出意图，情感，话题，观点

2020.06.24
学术思维，分而化之，找到最关键的点；工程思维，集众家之所长，解决实际问题

2020.6.18
我的个人永生机器人理想跟微软小冰很像。人格的定义：人格（personality）是指个体在对人、对事、
对己等方面的社会适应中行为上的内部倾向性和心理特征。表现为能力、气质、性格、需要、动机、兴趣、
理想、价值观和体质等方面的整合，是具有动力一致性和连续性的自我，是个体在社会化过程中形成的
独特的心身组织。整体性、稳定性、独特性和社会性是人格的基本特征


2020.06.12
有VD-BERT和audio-bert，距离真正的机器人更近了一步。

2020.06.11
预训练模型给小公司方便的同时，也限制了效果的上限，因为小公司不会轻易重新预训练模型，应该有一个更加性价比的预训练方式

2020.05.21
知识蒸馏：在满足速度速度前期下，同构和异构模型，哪个效果更好（soto）

2020.0518
通过这几天对tenserflow的优化，结果都不太好，所以说出现了国内的开源框架，可定是有原因的

2020.05.12
预训练是知识提取的过程，能不能直接的知识注入呢？

2020.05.06
attention 是否可以把上句（甚至双方前对话）和当前句一起输入模型呢？

2020.04.29
bert中的MLM从某种意义上也是一种标签，不是绝对意义的无监督训练

2020.04.27
Attention的本质是根据事物之间的关系进行线性加权得到新的表示

2020.4.15
大模型，是大企业的优势；高性价比模型，少数据，迁移才是中小企业的方向

2020.04.09
喜欢做的用好奇心做好
不喜欢做的用责任心做好

2020.04.03
训练要给出模型的有效分数范围
2020.0401
不确定结果解决确定问题

2020.02.26
目标驱动的研究：将自己定义在通用解决方案中
根据经验来说，过于频繁地切换想法比呆在原地不动的故障概率更高
所以可以采取一种策略，设置固定的时间去尝试那些新想法，比如每周花一天时间去探索和自己现在所从事项目完全不同的想法，这样也有利于拓宽知识面。
你应该拨出一部分时间来继续充实机器学习领域的一般性知识.教材书一般以一种更集中的方式来吸取知识。

